# -*- coding: utf-8 -*-
"""audio_to_visual_prototype_mk1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XtjFQnesFYeFSygeVwWFM8lhlrQrXKhD
"""

# Install libraries

!pip install librosa opencv-python matplotlib
!apt-get install ffmpeg

"""##Import libraries"""

# Load and extract audio features
import os
import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
import cv2
import psutil

"""##Hook-up Google Drive"""

from google.colab import drive
drive.mount('/content/drive')

"""##Load and Extract Audio Features"""

# Define frame dimensions and parameters
frame_width, frame_height = 640, 480  # Define video resolution
num_shapes = 5  # Number of dynamic shapes

# Load full audio file
audio_path = "/content/drive/MyDrive/sumu - apart [NCS Release].wav"
y, sr = librosa.load(audio_path, sr=22050)  # Load the full audio file
print(f"Loaded audio length: {librosa.get_duration(y=y, sr=sr)} seconds")

# Extract features
rms = librosa.feature.rms(y=y)[0]
spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)[0]

# Normalize features
if len(rms) > 0 and len(spectral_centroid) > 0:
    rms_norm = [val / max(rms) for val in rms]
    spectral_centroid_norm = [val / max(spectral_centroid) for val in spectral_centroid]
else:
    print("Error: No valid features extracted. Check your audio file.")
    exit()

# Check total frames
print(f"Number of frames: {len(rms_norm)}")
print(f"Expected frames for 142 seconds: {int((sr * 142) / 512)}")  # 512 = default hop length

# Calculate FPS dynamically based on the audio duration
fps = len(rms_norm) / 142  # Adjust frame rate to match 142 seconds (audio duration)
print(f"Calculated FPS: {fps}")

# Initialize video writer with dynamic FPS
out = cv2.VideoWriter('output.avi', cv2.VideoWriter_fourcc(*'XVID'), fps, (frame_width, frame_height))

# Main visualization loop
for i in range(len(rms_norm)):  # Process all frames
    print(f"Processing frame {i + 1}/{len(rms_norm)}")

    # Create a blank frame
    frame = np.zeros((frame_height, frame_width, 3), dtype=np.uint8)

    # Map audio features to parameters
    size = int(rms_norm[i] * 200)
    freq_color = (
        int(spectral_centroid_norm[i] * 255),  # Red
        int((1 - spectral_centroid_norm[i]) * 255),  # Green
        150  # Blue remains constant
    )
    speed = int(spectral_centroid_norm[i] * 20) + 5  # Movement speed

    # Draw multiple shapes
    for j in range(num_shapes):
        x = (i * speed + j * 50) % frame_width  # Horizontal movement
        y = int((frame_height / 2) + (np.sin(i * 0.1 + j) * 100))  # Vertical oscillation

        if j % 2 == 0:
            cv2.circle(frame, (x, y), size, freq_color, -1)  # Draw circle
        else:
            top_left = (x - size // 2, y - size // 2)
            bottom_right = (x + size // 2, y + size // 2)
            cv2.rectangle(frame, top_left, bottom_right, freq_color, -1)  # Draw rectangle

    # Write the frame to the video
    out.write(frame)

# Release the video writer
out.release()
print("Video saved as output.avi")

# Add audio to the video using FFmpeg
!ffmpeg -i output.avi -i "/content/drive/MyDrive/sumu - apart [NCS Release].wav" -c:v copy -c:a aac -strict experimental output_with_audio.mp4

# Download the final video
from google.colab import files
files.download('output_with_audio.mp4')
